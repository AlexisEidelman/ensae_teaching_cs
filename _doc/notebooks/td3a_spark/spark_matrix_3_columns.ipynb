{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Matrice en 3 colonnes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"my_id_menu_nb\">run previous cell, wait for 2 seconds</div>\n",
              "<script>\n",
              "function repeat_indent_string(n){\n",
              "    var a = \"\" ;\n",
              "    for ( ; n > 0 ; --n) {\n",
              "        a += \"    \";\n",
              "    }\n",
              "    return a;\n",
              "}\n",
              "var update_menu_string = function(begin, lfirst, llast, sformat, send, keep_item) {\n",
              "    var anchors = document.getElementsByClassName(\"section\");\n",
              "    if (anchors.length == 0) {\n",
              "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
              "    }\n",
              "    var i,t;\n",
              "    var text_menu = begin;\n",
              "    var text_memo = \"<pre>\\nlength:\" + anchors.length + \"\\n\";\n",
              "    var ind = \"\";\n",
              "    var memo_level = 1;\n",
              "    var href;\n",
              "    var tags = [];\n",
              "    var main_item = 0;\n",
              "    for (i = 0; i <= llast; i++) {\n",
              "        tags.push(\"h\" + i);\n",
              "    }\n",
              "\n",
              "    for (i = 0; i < anchors.length; i++) {\n",
              "        text_memo += \"**\" + anchors[i].id + \"--\\n\";\n",
              "\n",
              "        var child = null;\n",
              "        for(t = 0; t < tags.length; t++) {\n",
              "            var r = anchors[i].getElementsByTagName(tags[t]);\n",
              "            if (r.length > 0) {\n",
              "child = r[0];\n",
              "break;\n",
              "            }\n",
              "        }\n",
              "        if (child == null){\n",
              "            text_memo += \"null\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        if (anchors[i].hasAttribute(\"id\")) {\n",
              "            // when converted in RST\n",
              "            href = anchors[i].id;\n",
              "            text_memo += \"#1-\" + href;\n",
              "            // passer \u00e0 child suivant (le chercher)\n",
              "        }\n",
              "        else if (child.hasAttribute(\"id\")) {\n",
              "            // in a notebook\n",
              "            href = child.id;\n",
              "            text_memo += \"#2-\" + href;\n",
              "        }\n",
              "        else {\n",
              "            text_memo += \"#3-\" + \"*\" + \"\\n\";\n",
              "            continue;\n",
              "        }\n",
              "        var title = child.textContent;\n",
              "        var level = parseInt(child.tagName.substring(1,2));\n",
              "\n",
              "        text_memo += \"--\" + level + \"?\" + lfirst + \"--\" + title + \"\\n\";\n",
              "\n",
              "        if ((level < lfirst) || (level > llast)) {\n",
              "            continue ;\n",
              "        }\n",
              "        if (title.endsWith('\u00b6')) {\n",
              "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\")\n",
              "        }\n",
              "\n",
              "        if (title.length == 0) {\n",
              "            continue;\n",
              "        }\n",
              "\n",
              "        while (level < memo_level) {\n",
              "            text_menu += \"</ul>\\n\";\n",
              "            memo_level -= 1;\n",
              "        }\n",
              "        if (level == lfirst) {\n",
              "            main_item += 1;\n",
              "        }\n",
              "        if (keep_item != -1 && main_item != keep_item + 1) {\n",
              "            // alert(main_item + \" - \" + level + \" - \" + keep_item);\n",
              "            continue;\n",
              "        }\n",
              "        while (level > memo_level) {\n",
              "            text_menu += \"<ul>\\n\";\n",
              "            memo_level += 1;\n",
              "        }\n",
              "        text_menu += repeat_indent_string(level-2) + sformat.replace(\"__HREF__\", href).replace(\"__TITLE__\", title);\n",
              "    }\n",
              "    while (1 < memo_level) {\n",
              "        text_menu += \"</ul>\\n\";\n",
              "        memo_level -= 1;\n",
              "    }\n",
              "    text_menu += send;\n",
              "    //text_menu += \"\\n\" + text_memo;\n",
              "    return text_menu;\n",
              "};\n",
              "var update_menu = function() {\n",
              "    var sbegin = \"\";\n",
              "    var sformat = '<li><a href=\"#__HREF__\">__TITLE__</a></li>';\n",
              "    var send = \"\";\n",
              "    var keep_item = -1;\n",
              "    var text_menu = update_menu_string(sbegin, 2, 4, sformat, send, keep_item);\n",
              "    var menu = document.getElementById(\"my_id_menu_nb\");\n",
              "    menu.innerHTML=text_menu;\n",
              "};\n",
              "window.setTimeout(update_menu,2000);\n",
              "            </script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from jyquickhelper import add_notebook_menu\n",
        "add_notebook_menu()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ce notebook propose d'impl\u00e9menter un produit matriciel sous Spark. Spark comme SQL n'aime pas trop avoir un nombre de colonnes variables. La premi\u00e8re \u00e9tape consiste \u00e0 transformer les matrices $I\\times J$ en tableau de trois colonnes $(i,j,coefficient)$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cr\u00e9ation d'une matrice al\u00e9atoire"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.49193185,  1.93124783],\n",
              "       [ 3.67023704,  3.16655504],\n",
              "       [ 2.37311039,  2.38221324],\n",
              "       [ 2.25001061,  2.60441484],\n",
              "       [ 2.79618265,  2.98784145],\n",
              "       [ 2.4902488 ,  1.72328881],\n",
              "       [ 2.61943371,  2.22717208],\n",
              "       [ 2.83936229,  2.9615508 ],\n",
              "       [ 2.3475777 ,  2.24761376],\n",
              "       [ 3.02640224,  2.27159035]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from numpy.random import rand\n",
        "rnd1 = rand(10,10)\n",
        "rnd2 = rand(10, 2)\n",
        "rnd1 @ rnd2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.825367</td>\n",
              "      <td>0.104939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.257015</td>\n",
              "      <td>0.241694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.039147</td>\n",
              "      <td>0.789518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.491701</td>\n",
              "      <td>0.153167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.872270</td>\n",
              "      <td>0.309497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.786646</td>\n",
              "      <td>0.685438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.453832</td>\n",
              "      <td>0.876692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.862785</td>\n",
              "      <td>0.496380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.624780</td>\n",
              "      <td>0.481755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.570678</td>\n",
              "      <td>0.779402</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1\n",
              "0  0.825367  0.104939\n",
              "1  0.257015  0.241694\n",
              "2  0.039147  0.789518\n",
              "3  0.491701  0.153167\n",
              "4  0.872270  0.309497\n",
              "5  0.786646  0.685438\n",
              "6  0.453832  0.876692\n",
              "7  0.862785  0.496380\n",
              "8  0.624780  0.481755\n",
              "9  0.570678  0.779402"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas\n",
        "df1 = pandas.DataFrame(rnd1)\n",
        "df2 = pandas.DataFrame(rnd2)\n",
        "df2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df1.to_csv(\"rnd1.txt\", sep=\"\\t\", header=None, index=False)\n",
        "df2.to_csv(\"rnd2.txt\", sep=\"\\t\", header=None, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conversion d'une matrice au format Spark\n",
        "\n",
        "Lorsqu'un traitement est distribu\u00e9 en Map/Reduce, il n'est pas possible de s'appuyer sur l'ordre dans lequel sont trait\u00e9es les lignes. Le plus est d'ajouter cette information sur chaque ligne plut\u00f4t que de chercher \u00e0 la r\u00e9cup\u00e9rer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df1.to_csv(\"rnd1.txt\", sep=\"\\t\", header=None, index=True)\n",
        "df2.to_csv(\"rnd2.txt\", sep=\"\\t\", header=None, index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "def process_mat_row(row):\n",
        "    values = row.split(\"\\t\")\n",
        "    index = int(values[0])\n",
        "    values = [float(_) for _ in values[1:]]\n",
        "    return [[index, j, v] for j, v in enumerate(values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 0, 0.7073669487056997],\n",
              " [0, 1, 0.38049053626197293],\n",
              " [0, 2, 0.05182708138929548],\n",
              " [0, 3, 0.3599397323172999],\n",
              " [0, 4, 0.17035816004085025],\n",
              " [0, 5, 0.7665995035596439],\n",
              " [0, 6, 0.5334680552689206],\n",
              " [0, 7, 0.12390850009936782],\n",
              " [0, 8, 0.438956360362891],\n",
              " [0, 9, 0.44926935830522163],\n",
              " [1, 0, 0.5458627444692511],\n",
              " [1, 1, 0.05686919336554841]]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mat1 = sc.textFile(\"rnd1.txt\")\n",
        "new_mat1 = mat1.flatMap(process_mat_row)\n",
        "new_mat1.take(12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[0, 0, 0.8253673414743797],\n",
              " [0, 1, 0.10493947274099424],\n",
              " [1, 0, 0.25701493053720903],\n",
              " [1, 1, 0.24169374169340407],\n",
              " [2, 0, 0.039147207879637436],\n",
              " [2, 1, 0.7895175542881998],\n",
              " [3, 0, 0.4917011886170065],\n",
              " [3, 1, 0.15316743917896902],\n",
              " [4, 0, 0.8722700195595767],\n",
              " [4, 1, 0.30949671566398185],\n",
              " [5, 0, 0.7866459425892333],\n",
              " [5, 1, 0.6854376344061859]]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mat2 = sc.textFile(\"rnd2.txt\")\n",
        "new_mat2 = mat2.flatMap(process_mat_row)\n",
        "new_mat2.take(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Produit matriciel\n",
        "\n",
        "Il faut d'abord faire la jointure avec la m\u00e9thode [join](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.join). Il faut que la cl\u00e9 soit sur la premi\u00e8re colonne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, ((0, 0.7073669487056997), (0, 0.8253673414743797))),\n",
              " (0, ((0, 0.7073669487056997), (1, 0.10493947274099424))),\n",
              " (0, ((1, 0.5458627444692511), (0, 0.8253673414743797))),\n",
              " (0, ((1, 0.5458627444692511), (1, 0.10493947274099424))),\n",
              " (0, ((2, 0.7991774982704423), (0, 0.8253673414743797))),\n",
              " (0, ((2, 0.7991774982704423), (1, 0.10493947274099424))),\n",
              " (0, ((3, 0.786288741719609), (0, 0.8253673414743797))),\n",
              " (0, ((3, 0.786288741719609), (1, 0.10493947274099424))),\n",
              " (0, ((4, 0.6679236875594428), (0, 0.8253673414743797))),\n",
              " (0, ((4, 0.6679236875594428), (1, 0.10493947274099424))),\n",
              " (0, ((5, 0.595595156523955), (0, 0.8253673414743797))),\n",
              " (0, ((5, 0.595595156523955), (1, 0.10493947274099424)))]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def key_ij(row):\n",
        "    return row[0], (row[1], row[2])\n",
        "def key_ji(row):\n",
        "    return row[1], (row[0], row[2])\n",
        "mat_join = new_mat1.map(key_ji).join(new_mat2.map(key_ij))\n",
        "mat_join.take(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On effectue le produit matriciel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(0, 0, 0.5838375779000673),\n",
              " (0, 1, 0.07423071463158205),\n",
              " (1, 0, 0.45053728221249445),\n",
              " (1, 1, 0.057282548593555284),\n",
              " (2, 0, 0.6596150071136206),\n",
              " (2, 1, 0.08386526529496705),\n",
              " (3, 0, 0.6489770483843489),\n",
              " (3, 1, 0.08251272597823557),\n",
              " (4, 0, 0.5512823983087015),\n",
              " (4, 1, 0.0700915596037085),\n",
              " (5, 0, 0.4915847909351938),\n",
              " (5, 1, 0.06250144169271378)]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def produit_matriciel(row):\n",
        "    index, ((i, v1), (j, v2)) = row\n",
        "    return i, j, v1 * v2\n",
        "produit = mat_join.map(produit_matriciel)\n",
        "produit.take(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il ne reste plus qu'\u00e0 agr\u00e9ger [reduceByKey](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey). La documentation fournit un exemple facilement transposable. Elle indique aussi : *Merge the values for each key using an associative and commutative reduce function.* Pourquoi pr\u00e9cise-t-elle **associative et commutative** ? Cela signifie que le r\u00e9sultat ne d\u00e9pend pas de l'ordre dans lequel l'agr\u00e9gation est r\u00e9alis\u00e9e et qu'on peut commencer \u00e0 agr\u00e9ger sans attendre d'avoir regroup\u00e9 toutes les valeurs associ\u00e9es \u00e0 une cl\u00e9.\n",
        "\n",
        "* *Cas 1 :* [groupBy](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.groupBy) + agr\u00e9gation qui commence une fois les valeurs regroup\u00e9es\n",
        "* *Cas 2 :* [reduceByKey](http://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD.reduceByKey) + agr\u00e9gation qui commence d\u00e8s les premi\u00e8res valeurs regroup\u00e9es\n",
        "\n",
        "Le cas 2 est moins consommateur en terme de donn\u00e9es. Le cas 1 n'est possible que si les valeurs agr\u00e9g\u00e9es ne sont pas trop nombreuses. Ca tombe bien, dans notre cas, le cas 2 convient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "scrolled": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[((0, 0), 2.4919318533320625),\n",
              " ((0, 1), 1.9312478315672568),\n",
              " ((1, 0), 3.670237041775416),\n",
              " ((1, 1), 3.166555036937517),\n",
              " ((2, 0), 2.373110393276501),\n",
              " ((2, 1), 2.3822132377173104),\n",
              " ((3, 0), 2.2500106053379922),\n",
              " ((3, 1), 2.6044148377063303),\n",
              " ((4, 0), 2.7961826479381813),\n",
              " ((4, 1), 2.9878414514656617),\n",
              " ((5, 0), 2.490248798137291),\n",
              " ((5, 1), 1.7232888136146995),\n",
              " ((6, 0), 2.619433710358372),\n",
              " ((6, 1), 2.227172080670293),\n",
              " ((7, 0), 2.8393622934115),\n",
              " ((7, 1), 2.961550804570348),\n",
              " ((8, 0), 2.3475776976381812),\n",
              " ((8, 1), 2.247613763833498),\n",
              " ((9, 0), 3.0264022424819412),\n",
              " ((9, 1), 2.271590353117718)]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import add\n",
        "final = produit.map(lambda row: ((row[0], row[1]), row[2])).reduceByKey(add)\n",
        "aslist = final.collect()\n",
        "aslist.sort()\n",
        "aslist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "R\u00e9sultat initial :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 2.49193185,  1.93124783],\n",
              "       [ 3.67023704,  3.16655504],\n",
              "       [ 2.37311039,  2.38221324],\n",
              "       [ 2.25001061,  2.60441484],\n",
              "       [ 2.79618265,  2.98784145],\n",
              "       [ 2.4902488 ,  1.72328881],\n",
              "       [ 2.61943371,  2.22717208],\n",
              "       [ 2.83936229,  2.9615508 ],\n",
              "       [ 2.3475777 ,  2.24761376],\n",
              "       [ 3.02640224,  2.27159035]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnd1 @ rnd2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}