{
 "metadata": {
  "name": "",
  "signature": "sha256:bffa00a659318ed1181d42355d5fba8a0967f01ef5a7c36b2047310f039bc844"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "S\u00e9ance 6 : Map/Reduce avec PIG"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plan\n",
      "\n",
      "- [Exercice 1 : GROUP BY](#exo1)\n",
      "- [Exercice 2 : JOIN](#exo2)\n",
      "- [Prolongements](#prol)\n",
      "\n",
      "<div style=\"position:absolute; top:10px; right:5px; width:100px; margin:10px; background-color:#DDDDDD;\">\n",
      "[Exo 1 : GROUP BY](#exo1) -- [Exo 2 : JOIN](#exo2) -- [Prolongements](#prol)\n",
      "</div>\n",
      "\n",
      "On consid\u00e8re le jeu de donn\u00e9es suivant : [Localization Data for Person Activity Data Set](https://archive.ics.uci.edu/ml/datasets/Localization+Data+for+Person+Activity) qu'on r\u00e9cup\u00e8re comme suit :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyquickhelper, pyensae\n",
      "params={\"server\":\"\", \"username\":\"dz...fr\", \"password\":\"\"}\n",
      "pyquickhelper.open_html_form(params=params,title=\"server + credentials\", key_save=\"params\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"background-color:gainsboro; padding:2px; border:0px;\"><b>server + credentials</b>\n",
        "<br />password <input type=\"password\" id=\"paramspassword\" value=\"\" size=\"80\" />\n",
        "<br />server <input type=\"text\" id=\"paramsserver\" value=\"\" size=\"80\" />\n",
        "<br />username <input type=\"text\" id=\"paramsusername\" value=\"dz...fr\" size=\"80\" />\n",
        "<br /><button onclick=\"set_valueparams()\">Ok</button></div>\n",
        "<script type=\"text/Javascript\">\n",
        "function set_valueparams(){\n",
        "   command='params = {' ;\n",
        "   var paramspasswordvar_value = document.getElementById('paramspassword').value;\n",
        "   command += '\"password\":\"' + paramspasswordvar_value + '\",';\n",
        "   var paramsservervar_value = document.getElementById('paramsserver').value;\n",
        "   command += '\"server\":\"' + paramsservervar_value + '\",';\n",
        "   var paramsusernamevar_value = document.getElementById('paramsusername').value;\n",
        "   command += '\"username\":\"' + paramsusernamevar_value + '\",';\n",
        "   command += '}';\n",
        "   var kernel = IPython.notebook.kernel;\n",
        "   kernel.execute(command);\n",
        "}\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "<IPython.core.display.HTML at 0x7342a50>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "password = params[\"password\"]\n",
      "server = params[\"server\"]\n",
      "username = params[\"username\"]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_open"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<pyensae.remote.remote_connection.ASSHClient at 0xa201a50>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"exo1\">Exercice 1 : GROUP BY</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas, sqlite3\n",
      "con = sqlite3.connect(\"ConfLongDemo_JSI.db3\")\n",
      "df = pandas.read_sql(\"\"\"SELECT activity, count(*) as nb FROM person GROUP BY activity\"\"\", con)\n",
      "con.close()\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>activity</th>\n",
        "      <th>nb</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      falling</td>\n",
        "      <td>  2973</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>        lying</td>\n",
        "      <td> 54480</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   lying down</td>\n",
        "      <td>  6168</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> on all fours</td>\n",
        "      <td>  5210</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>      sitting</td>\n",
        "      <td> 27244</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "       activity     nb\n",
        "0       falling   2973\n",
        "1         lying  54480\n",
        "2    lying down   6168\n",
        "3  on all fours   5210\n",
        "4       sitting  27244"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Il faut maintenant le faire avec PIG."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG solution_groupby.pig\n",
      "\n",
      "myinput = LOAD 'ConfLongDemo_JSI.small.example.txt' \n",
      "          using PigStorage(',') \n",
      "          AS (index:long, sequence, tag, timestamp:long, dateformat, x:double,y:double, z:double, activity) ;\n",
      "\n",
      "gr = GROUP myinput BY activity ;\n",
      "avgact = FOREACH gr GENERATE group, COUNT(myinput) ; \n",
      "\n",
      "STORE avgact INTO 'ConfLongDemo_JSI.small.group.txt' USING PigStorage() ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%jobsubmit solution_groupby.pig groupby.redirection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<IPython.core.display.HTML at 0x6fb96d8>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd tail groupby.redirection.err"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "Total bytes written : 89\n",
        "Spillable Memory Manager spill count : 0\n",
        "Total bags proactively spilled: 0\n",
        "Total records proactively spilled: 0\n",
        "\n",
        "Job DAG:\n",
        "job_1410345524631_0011\n",
        "\n",
        "\n",
        "2014-10-25 00:26:50,476 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "<IPython.core.display.HTML at 0x9139080>"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd hdfs dfs -ls ConfLongDemo_JSI.small.group.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "Found 2 items\n",
        "-rw-r--r--   3 xavierdupre xavierdupre          0 2014-10-25 00:26 ConfLongDemo_JSI.small.group.txt/_SUCCESS\n",
        "-rw-r--r--   3 xavierdupre xavierdupre         89 2014-10-25 00:26 ConfLongDemo_JSI.small.group.txt/part-r-00000\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<IPython.core.display.HTML at 0x91390f0>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd hdfs dfs -tail ConfLongDemo_JSI.small.group.txt/part-r-00000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "lying\t267\n",
        "falling\t30\n",
        "sitting\t435\n",
        "walking\t170\n",
        "sitting down\t56\n",
        "standing up from sitting\t42\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "<IPython.core.display.HTML at 0x9139128>"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"exo2\">Exercice 2 : JOIN</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "con = sqlite3.connect(\"ConfLongDemo_JSI.db3\")\n",
      "df = pandas.read_sql(\"\"\"SELECT person.*, A.nb FROM person INNER JOIN (\n",
      "                            SELECT activity, count(*) as nb FROM person GROUP BY activity) AS A\n",
      "                            ON person.activity == A.activity\"\"\", con)\n",
      "con.close()\n",
      "df.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>index</th>\n",
        "      <th>sequence</th>\n",
        "      <th>tag</th>\n",
        "      <th>timestamp</th>\n",
        "      <th>dateformat</th>\n",
        "      <th>x</th>\n",
        "      <th>y</th>\n",
        "      <th>z</th>\n",
        "      <th>activity</th>\n",
        "      <th>nb</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 0</td>\n",
        "      <td> A01</td>\n",
        "      <td> 010-000-024-033</td>\n",
        "      <td> 633790226051280329</td>\n",
        "      <td> 27.05.2009 14:03:25:127</td>\n",
        "      <td> 4.062931</td>\n",
        "      <td> 1.892434</td>\n",
        "      <td> 0.507425</td>\n",
        "      <td> walking</td>\n",
        "      <td> 32710</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 1</td>\n",
        "      <td> A01</td>\n",
        "      <td> 020-000-033-111</td>\n",
        "      <td> 633790226051820913</td>\n",
        "      <td> 27.05.2009 14:03:25:183</td>\n",
        "      <td> 4.291954</td>\n",
        "      <td> 1.781140</td>\n",
        "      <td> 1.344495</td>\n",
        "      <td> walking</td>\n",
        "      <td> 32710</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 2</td>\n",
        "      <td> A01</td>\n",
        "      <td> 020-000-032-221</td>\n",
        "      <td> 633790226052091205</td>\n",
        "      <td> 27.05.2009 14:03:25:210</td>\n",
        "      <td> 4.359101</td>\n",
        "      <td> 1.826456</td>\n",
        "      <td> 0.968821</td>\n",
        "      <td> walking</td>\n",
        "      <td> 32710</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td> 3</td>\n",
        "      <td> A01</td>\n",
        "      <td> 010-000-024-033</td>\n",
        "      <td> 633790226052361498</td>\n",
        "      <td> 27.05.2009 14:03:25:237</td>\n",
        "      <td> 4.087835</td>\n",
        "      <td> 1.879999</td>\n",
        "      <td> 0.466983</td>\n",
        "      <td> walking</td>\n",
        "      <td> 32710</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 4</td>\n",
        "      <td> A01</td>\n",
        "      <td> 010-000-030-096</td>\n",
        "      <td> 633790226052631792</td>\n",
        "      <td> 27.05.2009 14:03:25:263</td>\n",
        "      <td> 4.324462</td>\n",
        "      <td> 2.072460</td>\n",
        "      <td> 0.488065</td>\n",
        "      <td> walking</td>\n",
        "      <td> 32710</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "   index sequence              tag           timestamp  \\\n",
        "0      0      A01  010-000-024-033  633790226051280329   \n",
        "1      1      A01  020-000-033-111  633790226051820913   \n",
        "2      2      A01  020-000-032-221  633790226052091205   \n",
        "3      3      A01  010-000-024-033  633790226052361498   \n",
        "4      4      A01  010-000-030-096  633790226052631792   \n",
        "\n",
        "                dateformat         x         y         z activity     nb  \n",
        "0  27.05.2009 14:03:25:127  4.062931  1.892434  0.507425  walking  32710  \n",
        "1  27.05.2009 14:03:25:183  4.291954  1.781140  1.344495  walking  32710  \n",
        "2  27.05.2009 14:03:25:210  4.359101  1.826456  0.968821  walking  32710  \n",
        "3  27.05.2009 14:03:25:237  4.087835  1.879999  0.466983  walking  32710  \n",
        "4  27.05.2009 14:03:25:263  4.324462  2.072460  0.488065  walking  32710  "
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Idem, maintenant il faut le faire avec PIG."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG solution_groupby_join.pig\n",
      "\n",
      "myinput = LOAD 'ConfLongDemo_JSI.small.example.txt' \n",
      "          using PigStorage(',') \n",
      "          AS (index:long, sequence, tag, timestamp:long, dateformat, x:double,y:double, z:double, activity) ;\n",
      "\n",
      "gr = GROUP myinput BY activity ;\n",
      "avgact = FOREACH gr GENERATE group, COUNT(myinput) ; \n",
      "\n",
      "joined = JOIN myinput BY activity, avgact BY group ;\n",
      "\n",
      "STORE joined INTO 'ConfLongDemo_JSI.small.group.join.txt' USING PigStorage() ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%jobsubmit solution_groupby_join.pig groupby.join.redirection"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 28,
       "text": [
        "<IPython.core.display.HTML at 0x6fb9748>"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd tail groupby.join.redirection.err"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "job_1410345524631_0012\t->\tjob_1410345524631_0013,\n",
        "job_1410345524631_0013\n",
        "\n",
        "\n",
        "2014-10-25 00:58:26,919 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: dn03.dzr323.dza.datazoomr.com/10.58.223.23:60910. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)\n",
        "2014-10-25 00:58:27,920 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: dn03.dzr323.dza.datazoomr.com/10.58.223.23:60910. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)\n",
        "2014-10-25 00:58:28,922 [main] INFO  org.apache.hadoop.ipc.Client - Retrying connect to server: dn03.dzr323.dza.datazoomr.com/10.58.223.23:60910. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)\n",
        "2014-10-25 00:58:29,039 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
        "2014-10-25 00:58:29,254 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
        "2014-10-25 00:58:29,400 [main] INFO  org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher - Success!\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "<IPython.core.display.HTML at 0x9139c50>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd hdfs dfs -ls ConfLongDemo_JSI.small.group.join.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "Found 2 items\n",
        "-rw-r--r--   3 xavierdupre xavierdupre          0 2014-10-25 00:58 ConfLongDemo_JSI.small.group.join.txt/_SUCCESS\n",
        "-rw-r--r--   3 xavierdupre xavierdupre     144059 2014-10-25 00:58 ConfLongDemo_JSI.small.group.join.txt/part-r-00000\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 37,
       "text": [
        "<IPython.core.display.HTML at 0x91453c8>"
       ]
      }
     ],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%remote_cmd hdfs dfs -tail ConfLongDemo_JSI.small.group.join.txt/part-r-00000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "26262834000\t27.05.2009 14:03:46:283\t3.3038318157196045\t1.938292145729065\t0.7622964978218079\tstanding up from sitting\tstanding up from sitting\t42\n",
        "652\tA01\t020-000-033-111\t633790226262563704\t27.05.2009 14:03:46:257\t3.2363295555114746\t2.00623106956482\t1.1472841501235962\tstanding up from sitting\tstanding up from sitting\t42\n",
        "651\tA01\t010-000-030-096\t633790226262293413\t27.05.2009 14:03:46:230\t3.275949239730835\t1.7746492624282837\t0.3117055296897888\tstanding up from sitting\tstanding up from sitting\t42\n",
        "650\tA01\t010-000-024-033\t633790226262023117\t27.05.2009 14:03:46:203\t3.2498104572296143\t1.878917098045349\t0.13854867219924927\tstanding up from sitting\tstanding up from sitting\t42\n",
        "649\tA01\t020-000-032-221\t633790226261752823\t27.05.2009 14:03:46:177\t3.352446317672729\t1.950886845588684\t0.8281049728393555\tstanding up from sitting\tstanding up from sitting\t42\n",
        "648\tA01\t020-000-033-111\t633790226261482530\t27.05.2009 14:03:46:147\t3.2220029830932617\t2.0042579174041752\t1.032345414161682\tstanding up from sitting\tstanding up from sitting\t42\n",
        "\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 39,
       "text": [
        "<IPython.core.display.HTML at 0x9145518>"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"prol\">Prolongements</h3>\n",
      "\n",
      "[PIG](http://pig.apache.org/) n'est pas la seule fa\u00e7on d'ex\u00e9cuter des jobs Map/Reduce. [Hive](https://hive.apache.org/) est un langage dont la syntaxe est tr\u00e8s proche de celle du SQL. L'article [Comparing Pig Latin and SQL for Constructing Data Processing Pipelines](https://developer.yahoo.com/blogs/hadoop/comparing-pig-latin-sql-constructing-data-processing-pipelines-444.html) explicite les diff\u00e9rences des deux approches.\n",
      "\n",
      "**langage haut niveau**\n",
      "\n",
      "Ce qu'il faut retenir est que le langage PIG est un langage haut niveau. Le programme est compil\u00e9 en une s\u00e9quence d'op\u00e9rations Map/Reduce transparente pour l'utilisateur. Le temps de d\u00e9veloppement est tr\u00e8s r\u00e9duit lorsqu'on le compare au m\u00eame programme \u00e9crit en Java. Le compilateur construit un plan d'ex\u00e9cution ([quelques exemples ici](http://chimera.labs.oreilly.com/books/1234000001811/ch07.html#explain)) et inf\u00e8re le nombre de machines requises pour distribuer le job. Cela suffit pour la plupart des besoins, cela n\u00e9cessite.\n",
      "\n",
      "**petits jeux**\n",
      "\n",
      "Certains jobs peuvent durer des heures, il est conseill\u00e9e de les essayer sur des petits jeux de donn\u00e9es avant de les faire tourner sur les vrais donn\u00e9es. Il est toujours frustrant de s'apercevoir qu'un job a plant\u00e9 au bout de deux heures car une cha\u00eene de caract\u00e8res est vide et que ce cas n'a pas \u00e9t\u00e9 pr\u00e9vu.\n",
      "\n",
      "Avec ces petits jeux, il est possible de faire tourner et conseill\u00e9 de tester le job d'abord sur la passerelle ([ex\u00e9cution local](http://archive.cloudera.com/cdh/3/pig/tutorial.html#Running+the+Pig+Scripts+in+Local+Mode)) avant de le lancer sur le cluster. Avec pyensae, il faut ajouter l'option ``-local`` \u00e0 la commande ``jobsubmit``.\n",
      "\n",
      "**concat\u00e9ner les fichiers divis\u00e9s**\n",
      "\n",
      "Un programme PIG ne produit pas un fichier mais plusieurs fichiers dans un r\u00e9pertoire. La commande [getmerge](http://hadoop.apache.org/docs/r2.3.0/hadoop-project-dist/hadoop-common/FileSystemShell.html) t\u00e9l\u00e9charge ces fichiers sur la passerelle et les fusionne en un seul.\n",
      "\n",
      "**ordre des lignes**\n",
      "\n",
      "Les jobs sont distribu\u00e9s, m\u00eame en faisant rien (LOAD + STORE), il n'est pas garanti que l'ordre des lignes soit pr\u00e9serv\u00e9. La probabili\u00e9 que ce soit le cas est quasi nulle."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}