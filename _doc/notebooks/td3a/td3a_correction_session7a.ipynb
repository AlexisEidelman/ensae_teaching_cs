{
 "metadata": {
  "name": "",
  "signature": "sha256:212f364751c011b3328a80b1a399334f2e37b69ac048fa1ef6ac39d4524eac4e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "S\u00e9ance 7 : PIG et JSON avec les donn\u00e9es v\u00e9lib (correction)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Plan\n",
      "\n",
      "* [R\u00e9cup\u00e9ration des donn\u00e9es](#don)\n",
      "* [Conversion des donn\u00e9es](#conv)\n",
      "* [Connexion au cluster](#con)\n",
      "* [Exercice 1 : convertir les valeurs num\u00e9riques](#exo1)\n",
      "* [Exercice 2 : stations ferm\u00e9es](#exo2)\n",
      "* [Exercice 3 : stations ferm\u00e9es, journ\u00e9e compl\u00e8te](#exo3)\n",
      "\n",
      "\n",
      "<div style=\"position:absolute; top:10px; right:5px; width:100px; height:90px; margin:10px;\">\n",
      "[R\u00e9cup\u00e9ration](#don) -- [Conversion](#conv) -- [Connexion](#con) -- [Exo 1](#exo1) -- [Exo 2](#exo2) -- [Exo 3](#exo3)\n",
      "</div>\n",
      "\n",
      "<h3 id=\"don\">R\u00e9cup\u00e9ration des donn\u00e9es</h3>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyensae"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(\"velib\") : os.mkdir(\"velib\")\n",
      "files=pyensae.download_data(\"data_velib_paris_2014-11-11_22-23.zip\", website=\"xdtd\", whereTo=\"velib\")\n",
      "files[:2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['velib\\\\paris.2014-11-11_22-00-18.331391.txt',\n",
        " 'velib\\\\paris.2014-11-11_22-01-17.859194.txt']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"conv\">Conversion des donn\u00e9es</h3>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "folder = \"velib3\"\n",
      "if not os.path.exists(folder) : os.mkdir(folder)\n",
      "    \n",
      "import json\n",
      "class DateTimeEncoder(json.JSONEncoder):\n",
      "    def default(self, obj):\n",
      "        if isinstance(obj, datetime.datetime):\n",
      "            encoded_object = \"%04d-%02d-%02dT%02d:%02d:%02d\"% (obj.timetuple()[:6] )\n",
      "        else:\n",
      "            encoded_object =json.JSONEncoder.default(self, obj)\n",
      "        return encoded_object\n",
      "\n",
      "\n",
      "files = [ os.path.join(\"velib\",_) for _ in os.listdir(\"velib\") if \"paris\" in _ and _.endswith(\".txt\")]\n",
      "for f in files :\n",
      "    with open(f, \"r\", encoding=\"utf8\") as h : rows = h.readlines()\n",
      "    with open(os.path.join(folder, os.path.split(f)[-1]), \"w\", encoding=\"utf8\") as h:\n",
      "        for row in rows:\n",
      "            js = eval(row)\n",
      "            sjs = json.dumps( { \"minute\":js }, cls = DateTimeEncoder )\n",
      "            h.write( '%s\\n'% sjs )\n",
      "            \n",
      "# on v\u00e9rifie            \n",
      "with open(folder + \"/paris.2014-11-11_22-00-18.331391.txt\",\"r\",encoding=\"utf-8\")as f :\n",
      "    text = f.read()\n",
      "text[:300] + \"...\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'{\"minute\": [{\"contract_name\": \"Paris\", \"lat\": 48.8645278209514, \"collect_date\": \"2014-11-11T22:00:18\", \"last_update\": \"2014-11-11T21:55:22\", \"available_bikes\": 1, \"name\": \"31705 - CHAMPEAUX (BAGNOLET)\", \"lng\": 2.416170724425901, \"bonus\": 0, \"number\": 31705, \"address\": \"RUE DES CHAMPEAUX (PRES DE LA ...'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"con\">Connexion au cluster</h3>\n",
      "\n",
      "On prend le cluster [Azure](http://www.xavierdupre.fr/app/ensae_teaching_cs/helpsphinx3/notebooks/td3a_cenonce_session6b.html#p2)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyquickhelper, pyensae\n",
      "params={\"blob_storage\":\"\", \"password1\":\"\", \"hadoop_server\":\"\", \"password2\":\"\", \"username\":\"your_name\"}\n",
      "pyquickhelper.open_html_form(params=params,title=\"server + hadoop + credentials\", key_save=\"blobhp\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"background-color:gainsboro; padding:2px; border:0px;\"><b>server + hadoop + credentials</b>\n",
        "<br />blob_storage <input type=\"text\" id=\"blobhpblob_storage\" value=\"\" size=\"80\" />\n",
        "<br />hadoop_server <input type=\"text\" id=\"blobhphadoop_server\" value=\"\" size=\"80\" />\n",
        "<br />password1 <input type=\"password\" id=\"blobhppassword1\" value=\"\" size=\"80\" />\n",
        "<br />password2 <input type=\"password\" id=\"blobhppassword2\" value=\"\" size=\"80\" />\n",
        "<br />username <input type=\"text\" id=\"blobhpusername\" value=\"your_name\" size=\"80\" />\n",
        "<br /><button onclick=\"set_valueblobhp()\">Ok</button></div>\n",
        "<script type=\"text/Javascript\">\n",
        "function blobhpcallback(msg) {\n",
        "   var ret = msg.content.data['text/plain'];\n",
        "   $('#outblobhp').text(ret);\n",
        "}\n",
        "function set_valueblobhp(){\n",
        "   command='blobhp = {' ;\n",
        "   var blobhpblob_storagevar_value = document.getElementById('blobhpblob_storage').value;\n",
        "   command += '\"blob_storage\":\"' + blobhpblob_storagevar_value + '\",';\n",
        "   var blobhphadoop_servervar_value = document.getElementById('blobhphadoop_server').value;\n",
        "   command += '\"hadoop_server\":\"' + blobhphadoop_servervar_value + '\",';\n",
        "   var blobhppassword1var_value = document.getElementById('blobhppassword1').value;\n",
        "   command += '\"password1\":\"' + blobhppassword1var_value + '\",';\n",
        "   var blobhppassword2var_value = document.getElementById('blobhppassword2').value;\n",
        "   command += '\"password2\":\"' + blobhppassword2var_value + '\",';\n",
        "   var blobhpusernamevar_value = document.getElementById('blobhpusername').value;\n",
        "   command += '\"username\":\"' + blobhpusernamevar_value + '\",';\n",
        "   command += '}';\n",
        "   var kernel = IPython.notebook.kernel;\n",
        "   kernel.execute(command);\n",
        "}\n",
        "</script>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "<IPython.core.display.HTML at 0xb03f4f0>"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyensae\n",
      "blobstorage = blobhp[\"blob_storage\"]\n",
      "blobpassword = blobhp[\"password1\"]\n",
      "hadoop_server = blobhp[\"hadoop_server\"]\n",
      "hadoop_password = blobhp[\"password2\"]\n",
      "username = blobhp[\"username\"]\n",
      "cl, bs = %hd_open\n",
      "cl, bs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "(<pyensae.remote.azure_connection.AzureClient at 0x8310e30>,\n",
        " <azure.storage.blobservice.BlobService at 0x8310e50>)"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_ls hdblobstorage"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"exo1\">Exercice 1 : convertir les valeurs num\u00e9riques</h3>\n",
      "\n",
      "La premi\u00e8re option consiste \u00e0 changer le *sch\u00e9ma* JSON pour introduire la conversion des cha\u00eenes de caract\u00e8res en nombre. Mais lorsqu'on essaye le sch\u00e9ma suivant, une erreur survient :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG_azure json_cast.pig\n",
      "\n",
      "iminute = LOAD '__CONTAINER__velib3_small/paris.2014-11-11_22-56-17.319040.txt' \n",
      "        USING JsonLoader('minute:{(address:chararray,available_bike_stands:long,available_bikes:long,banking:long,bike_stands:long,bonus:chararray,collect_date:chararray,contract_name:chararray,last_update:chararray,lat:chararray,lng:chararray,name:chararray,number:chararray,status:chararray)}');\n",
      "station = FOREACH iminute GENERATE FLATTEN(minute) ;\n",
      "\n",
      "STORE station INTO '__CONTAINER__velib4_results/stations_small.txt' USING PigStorage('\\t') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%hd_pig_submit json_cast.pig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "{'id': 'job_1415772450618_0034'}"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Vous tomberez peut-\u00eatre sur un message du type :\n",
      "    \n",
      "``AttemptID:attempt_1415772450618_0035_m_000000_3 Info:Error: org.codehaus.jackson.JsonParseException: Current token (VALUE_STRING) not numeric, can not use numeric value accessors``"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%tail_stderr 50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<pre>\n",
        "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
        "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
        "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
        "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
        "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
        "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
        "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
        "\tat java.security.AccessController.doPrivileged(Native Method)\n",
        "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
        "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)\n",
        "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
        "\n",
        "2014-11-19 00:31:16,639 [main] <b><font color=\"#DD0000\">ERROR</font></b> org.apache.pig.tools.grunt.GruntParser - org.apache.pig.backend.executionengine.ExecException: <b><font color=\"#DD0000\">ERROR</font></b> 2997: Unable to recreate exception from backed error: AttemptID:attempt_1415772450618_0035_m_000000_3 Info:Error: org.codehaus.jackson.JsonParseException: Current token (VALUE_STRING) not numeric, can not use numeric value accessors\n",
        " at [Source: java.io.ByteArrayInputStream@7defafc8; line: 1, column: 80]\n",
        "\tat org.codehaus.jackson.JsonParser._constructError(JsonParser.java:1291)\n",
        "\tat org.codehaus.jackson.impl.JsonParserMinimalBase._reportError(JsonParserMinimalBase.java:385)\n",
        "\tat org.codehaus.jackson.impl.JsonNumericParserBase._parseNumericValue(JsonNumericParserBase.java:399)\n",
        "\tat org.codehaus.jackson.impl.JsonNumericParserBase.getLongValue(JsonNumericParserBase.java:268)\n",
        "\tat org.apache.pig.builtin.JsonLoader.readField(JsonLoader.java:206)\n",
        "\tat org.apache.pig.builtin.JsonLoader.readField(JsonLoader.java:309)\n",
        "\tat org.apache.pig.builtin.JsonLoader.getNext(JsonLoader.java:164)\n",
        "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigRecordReader.nextKeyValue(PigRecordReader.java:211)\n",
        "\tat org.apache.hadoop.mapred.MapTask$NewTrackingRecordReader.nextKeyValue(MapTask.java:533)\n",
        "\tat org.apache.hadoop.mapreduce.task.MapContextImpl.nextKeyValue(MapContextImpl.java:80)\n",
        "\tat org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.nextKeyValue(WrappedMapper.java:91)\n",
        "\tat org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:144)\n",
        "\tat org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:764)\n",
        "\tat org.apache.hadoop.mapred.MapTask.run(MapTask.java:340)\n",
        "\tat org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:168)\n",
        "\tat java.security.AccessController.doPrivileged(Native Method)\n",
        "\tat javax.security.auth.Subject.doAs(Subject.java:415)\n",
        "\tat org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1594)\n",
        "\tat org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:163)\n",
        "\n",
        "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher.getErrorMessages(Launcher.java:217)\n",
        "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.Launcher.getStats(Launcher.java:151)\n",
        "\tat org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.MapReduceLauncher.launchPig(MapReduceLauncher.java:429)\n",
        "\tat org.apache.pig.PigServer.launchPlan(PigServer.java:1324)\n",
        "\tat org.apache.pig.PigServer.executeCompiledLogicalPlan(PigServer.java:1309)\n",
        "\tat org.apache.pig.PigServer.execute(PigServer.java:1299)\n",
        "\tat org.apache.pig.PigServer.executeBatch(PigServer.java:377)\n",
        "\tat org.apache.pig.PigServer.executeBatch(PigServer.java:355)\n",
        "\tat org.apache.pig.tools.grunt.GruntParser.executeBatch(GruntParser.java:140)\n",
        "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:202)\n",
        "\tat org.apache.pig.tools.grunt.GruntParser.parseStopOnError(GruntParser.java:173)\n",
        "\tat org.apache.pig.tools.grunt.Grunt.exec(Grunt.java:84)\n",
        "\tat org.apache.pig.Main.run(Main.java:478)\n",
        "\tat org.apache.pig.Main.main(Main.java:156)\n",
        "\n",
        "Details also at logfile: C:\\apps\\dist\\hadoop-2.4.0.2.1.6.0-2103\\logs\\pig_1416357005741.log\n",
        "</pre>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 22,
       "text": [
        "<IPython.core.display.HTML at 0xb028af0>"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cela veut sans doute dire qu'on a des probl\u00e8mes de conversion de donn\u00e9es, on peut tenter quelque chose comme :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG_azure json_cast.pig\n",
      "\n",
      "iminute = LOAD '__CONTAINER__velib3_small/paris.2014-11-11_22-56-17.319040.txt' \n",
      "        USING JsonLoader('minute:{(address:chararray,available_bike_stands:chararray,available_bikes:chararray,banking:chararray,bike_stands:chararray,bonus:chararray,collect_date:chararray,contract_name:chararray,last_update:chararray,lat:chararray,lng:chararray,name:chararray,number:chararray,status:chararray)}');\n",
      "station = FOREACH iminute GENERATE FLATTEN(minute) ;\n",
      "istation = FOREACH station GENERATE \n",
      "                address,\n",
      "                (long)available_bike_stands AS available_bike_stands,\n",
      "                (long)available_bikes AS available_bikes,\n",
      "                (long)banking AS banking,\n",
      "                (long)bike_stands AS bike_stands,\n",
      "                (long)bonus AS bonus,\n",
      "                collect_date,\n",
      "                contract_name,\n",
      "                last_update,\n",
      "                (double)lat AS lat,\n",
      "                (double)lng AS lng,\n",
      "                name,\n",
      "                (long)number AS number,\n",
      "                status ;\n",
      "\n",
      "STORE istation INTO '__CONTAINER__velib6_results/stations_small.txt' USING PigStorage('\\t') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%hd_pig_submit json_cast.pig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "WindowsAzureError",
       "evalue": "Unknown error (Operation could not be completed within the specified time.)\n\ufeff<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>OperationTimedOut</Code><Message>Operation could not be completed within the specified time.\nRequestId:6a53f8c7-0001-0046-20f0-7d08dc000000\nTime:2014-11-19T00:58:45.1555234Z</Message></Error>",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mWindowsAzureError\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-e02cba038dac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hd_pig_submit json_cast.pig'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2203\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2204\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2205\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2207\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2124\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2125\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2126\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\xadupre\\__home_\\_data\\GitHub\\pyensae\\src\\pyensae\\remote\\magic_azure.py\u001b[0m in \u001b[0;36mhd_pig_submit\u001b[1;34m(self, line)\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\xadupre\\__home_\\_data\\GitHub\\pyensae\\src\\pyensae\\remote\\magic_azure.py\u001b[0m in \u001b[0;36mhd_pig_submit\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    485\u001b[0m             \u001b[0mcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_blob_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 486\u001b[1;33m             \u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremote\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    487\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpig_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccount_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mremote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstatus_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\xadupre\\__home_\\_data\\GitHub\\pyensae\\src\\pyensae\\remote\\azure_connection.py\u001b[0m in \u001b[0;36mupload\u001b[1;34m(self, blob_service, container_name, blob_name, file_path)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \"\"\"\n\u001b[0;32m    228\u001b[0m         \u001b[0mblob_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_container\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[0mblob_service\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput_blob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontainer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblob_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BlockBlob'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m         \u001b[0mblock_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\azure\\storage\\blobservice.py\u001b[0m in \u001b[0;36mput_blob\u001b[1;34m(self, container_name, blob_name, blob, x_ms_blob_type, content_encoding, content_language, content_md5, cache_control, x_ms_blob_content_type, x_ms_blob_content_encoding, x_ms_blob_content_language, x_ms_blob_content_md5, x_ms_blob_cache_control, x_ms_meta_name_values, x_ms_lease_id, x_ms_blob_content_length, x_ms_blob_sequence_number)\u001b[0m\n\u001b[0;32m    691\u001b[0m         request.headers = _update_storage_blob_header(\n\u001b[0;32m    692\u001b[0m             request, self.account_name, self.account_key)\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_perform_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     def put_block_blob_from_path(self, container_name, blob_name, file_path,\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\azure\\storage\\storageclient.py\u001b[0m in \u001b[0;36m_perform_request\u001b[1;34m(self, request, text_encoding)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[0m_storage_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\azure\\storage\\__init__.py\u001b[0m in \u001b[0;36m_storage_error_handler\u001b[1;34m(http_error)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_storage_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[1;34m''' Simple error handler for storage service. '''\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_general_error_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;31m# make these available just from storage.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Python34\\lib\\site-packages\\azure\\__init__.py\u001b[0m in \u001b[0;36m_general_error_handler\u001b[1;34m(http_error)\u001b[0m\n\u001b[0;32m    913\u001b[0m             raise WindowsAzureError(\n\u001b[0;32m    914\u001b[0m                 \u001b[0m_ERROR_UNKNOWN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m                     http_error.respbody.decode('utf-8'))\n\u001b[0m\u001b[0;32m    916\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mWindowsAzureError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ERROR_UNKNOWN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mWindowsAzureError\u001b[0m: Unknown error (Operation could not be completed within the specified time.)\n\ufeff<?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>OperationTimedOut</Code><Message>Operation could not be completed within the specified time.\nRequestId:6a53f8c7-0001-0046-20f0-7d08dc000000\nTime:2014-11-19T00:58:45.1555234Z</Message></Error>"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%tail_stderr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"exo2\">Exercice 2 : stations ferm\u00e9es</h3>\n",
      "    \n",
      "Les stations ferm\u00e9es ne le sont pas tout le temps. On veut calculer le ratio minutes/stations ferm\u00e9es / total des minutes/stations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%PIG_azure json_fermee.pig\n",
      "\n",
      "iminute = LOAD '__CONTAINER__velib3_small/paris.2014-11-11_22-56-17.319040.txt' \n",
      "        USING JsonLoader('minute:{(address:chararray,available_bike_stands:chararray,available_bikes:chararray,banking:chararray,bike_stands:chararray,bonus:chararray,collect_date:chararray,contract_name:chararray,last_update:chararray,lat:chararray,lng:chararray,name:chararray,number:chararray,status:chararray)}');\n",
      "station = FOREACH iminute GENERATE FLATTEN(minute) ;\n",
      "istation = FOREACH station GENERATE \n",
      "                address,\n",
      "                (long)available_bike_stands AS available_bike_stands,\n",
      "                (long)available_bikes AS available_bikes,\n",
      "                (long)banking AS banking,\n",
      "                (long)bike_stands AS bike_stands,\n",
      "                (long)bonus AS bonus,\n",
      "                collect_date,\n",
      "                contract_name,\n",
      "                last_update,\n",
      "                (double)lat AS lat,\n",
      "                (double)lng AS lng,\n",
      "                name,\n",
      "                (long)number AS number,\n",
      "                status ;\n",
      "                \n",
      "grstation = GROUP istation BY status ;  \n",
      "\n",
      "fermees = FOREACH grstation GENERATE\n",
      "                 group\n",
      "                ,SUM(istation.available_bikes) AS available_bikes\n",
      "                ,SUM(istation.available_bike_stands) AS available_bike_stands \n",
      "                ;\n",
      "\n",
      "\n",
      "STORE fermees INTO '__CONTAINER__velib8_results/stations_fermees.txt' USING PigStorage('\\t') ;\n",
      "\n",
      "gr_av   = GROUP istation BY available_bikes ;\n",
      "dist_av = FOREACH gr_av GENERATE group, COUNT(istation) ;\n",
      "gr_pl   = GROUP istation BY available_bike_stands ;\n",
      "dist_pl = FOREACH gr_pl GENERATE group, COUNT(istation) ;\n",
      "\n",
      "STORE dist_av INTO '__CONTAINER__velib8_results/distribution_bikes.txt' USING PigStorage('\\t') ;\n",
      "STORE dist_pl INTO '__CONTAINER__velib8_results/distribution_velos.txt' USING PigStorage('\\t') ;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%hd_pig_submit json_fermee.pig"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Line magic function `%hd_pig_submit` not found.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%tail_stderr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_downmerge velib8_results/distribution_bikes.txt\n",
      "%blob_downmerge velib8_results/distribution_bikes.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_downmerge"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%blob_downmerge"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h3 id=\"exo3\">Exercice 3 : stations ferm\u00e9es, journ\u00e9e compl\u00e8te</h3>\n",
      "    \n",
      "Appliquer cela \u00e0 une journ\u00e9e compl\u00e8te."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}