{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Factorisation de matrice avec PIG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "auteurs : *Théo Gantzer, Anna Korba*\n",
    "\n",
    "Ce travail s'appuie sur l'article [A Fast Distributed Stochastic Gradient Descent Algorithm for Matrix Factorization](http://www.jmlr.org/proceedings/papers/v36/li14.html), Fanglin Li, BinWu, Liutong Xu, Chuan Shi, and Jing Shi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Plan</b>\n",
       "<div id=\"my_menu_id\">run previous cell, wait for 2 seconds</div>\n",
       "<script>\n",
       "function repeat_indent_string(n){\n",
       "    var a = \"\" ;\n",
       "    for ( ; n > 0 ; --n) {\n",
       "        a += \"    \";\n",
       "    }\n",
       "    return a;\n",
       "}\n",
       "var update_menu = function() {\n",
       "    var anchors = document.getElementsByClassName(\"section\");\n",
       "    if (anchors.length == 0) {\n",
       "        anchors = document.getElementsByClassName(\"text_cell_render rendered_html\");\n",
       "    }\n",
       "    var i;\n",
       "    var text_menu = \"\";\n",
       "    var ind = \"\";\n",
       "    var memo_level = 1;\n",
       "    var href;\n",
       "    for (i = 0; i < anchors.length; i++) {\n",
       "        var child = anchors[i].children[0];\n",
       "        if (anchors[i].hasAttribute(\"id\")) {\n",
       "            href = anchors[i].id;\n",
       "        }\n",
       "        else if (child.hasAttribute(\"id\")) {\n",
       "            href = child.id;\n",
       "        }\n",
       "        else {\n",
       "            continue;\n",
       "        }\n",
       "        var title = child.textContent;\n",
       "        var level = parseInt(child.tagName.substring(1,2));\n",
       "        if ((level <= 2) || (level > 4)) {\n",
       "            continue ;\n",
       "        }\n",
       "        if (title.endsWith('¶')) {\n",
       "            title = title.substring(0,title.length-1).replace(\"<\", \"&lt;\").replace(\">\", \"&gt;\").replace(\"&\", \"&amp;\")\n",
       "        }\n",
       "        if (title.length == 0) {\n",
       "            continue;\n",
       "        }\n",
       "        while (level > memo_level) {\n",
       "            text_menu += \"<ul>\\n\";\n",
       "            memo_level += 1;\n",
       "        }\n",
       "        while (level < memo_level) {\n",
       "            text_menu += \"</ul>\\n\";\n",
       "            memo_level -= 1;\n",
       "        }\n",
       "        text_menu += repeat_indent_string(level-2) + '<li><a href=\"#' + href + '\">' + title + '</a></li>';\n",
       "    }\n",
       "    while (1 < memo_level) {\n",
       "        text_menu += \"</ul>\\n\";\n",
       "        memo_level -= 1;\n",
       "    }\n",
       "    text_menu += \"\";\n",
       "    var menu = document.getElementById(\"my_menu_id\");\n",
       "    menu.innerHTML=text_menu;\n",
       "};\n",
       "window.setTimeout(update_menu,2000);\n",
       "            </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyquickhelper.ipythonhelper import add_notebook_menu\n",
    "add_notebook_menu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connexion au cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"background-color:gainsboro; padding:2px; border:0px;\"><b>server + hadoop + credentials</b>\n",
       "<br />blob_storage <input type=\"text\" id=\"blobhpblob_storage\" value=\"\" size=\"80\" />\n",
       "<br />hadoop_server <input type=\"text\" id=\"blobhphadoop_server\" value=\"\" size=\"80\" />\n",
       "<br />password1 <input type=\"password\" id=\"blobhppassword1\" value=\"\" size=\"80\" />\n",
       "<br />password2 <input type=\"password\" id=\"blobhppassword2\" value=\"\" size=\"80\" />\n",
       "<br />username <input type=\"text\" id=\"blobhpusername\" value=\"alias\" size=\"80\" />\n",
       "<br /><button onclick=\"set_valueblobhp()\">Ok</button></div>\n",
       "<script type=\"text/Javascript\">\n",
       "function blobhpcallback(msg) {\n",
       "   var ret = msg.content.data['text/plain'];\n",
       "   $('#outblobhp').text(ret);\n",
       "}\n",
       "function set_valueblobhp(){\n",
       "   command='blobhp = {' ;\n",
       "   var blobhpblob_storagevar_value = document.getElementById('blobhpblob_storage').value;\n",
       "   command += '\"blob_storage\":\"' + blobhpblob_storagevar_value + '\",';\n",
       "   var blobhphadoop_servervar_value = document.getElementById('blobhphadoop_server').value;\n",
       "   command += '\"hadoop_server\":\"' + blobhphadoop_servervar_value + '\",';\n",
       "   var blobhppassword1var_value = document.getElementById('blobhppassword1').value;\n",
       "   command += '\"password1\":\"' + blobhppassword1var_value + '\",';\n",
       "   var blobhppassword2var_value = document.getElementById('blobhppassword2').value;\n",
       "   command += '\"password2\":\"' + blobhppassword2var_value + '\",';\n",
       "   var blobhpusernamevar_value = document.getElementById('blobhpusername').value;\n",
       "   command += '\"username\":\"' + blobhpusernamevar_value + '\",';\n",
       "   command += '}';\n",
       "   var kernel = IPython.notebook.kernel;\n",
       "   kernel.execute(command);\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyquickhelper, pyensae\n",
    "params={\"blob_storage\":\"\", \"password1\":\"\", \"hadoop_server\":\"\", \"password2\":\"\", \"username\":\"alias\"}\n",
    "pyquickhelper.ipythonhelper.open_html_form(params=params,title=\"server + hadoop + credentials\", key_save=\"blobhp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xaviermf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<pyensae.remote.azure_connection.AzureClient at 0x8c2b2b0>,\n",
       " <azure.storage.blobservice.BlobService at 0x8c2bf98>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyensae\n",
    "%load_ext pyensae\n",
    "blobstorage = blobhp[\"blob_storage\"]\n",
    "blobpassword = blobhp[\"password1\"]\n",
    "hadoop_server = blobhp[\"hadoop_server\"]\n",
    "hadoop_password = blobhp[\"password2\"]\n",
    "username = blobhp[\"username\"]\n",
    "print(username)\n",
    "client, bs =  %hd_open\n",
    "client, bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, url]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_ls /$PSEUDO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Téléchargment des données et transfert sur le cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    downloading of  http://files.grouplens.org/datasets/movielens/ml-1m.zip  to  ml-1m.zip\n",
      "    creating folder  .\\ml-1m\n",
      "    unzipped  ml-1m/movies.dat  to  .\\ml-1m/movies.dat\n",
      "    unzipped  ml-1m/ratings.dat  to  .\\ml-1m/ratings.dat\n",
      "    unzipped  ml-1m/README  to  .\\ml-1m/README\n",
      "    unzipped  ml-1m/users.dat  to  .\\ml-1m/users.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.\\\\ml-1m/movies.dat',\n",
       " '.\\\\ml-1m/ratings.dat',\n",
       " '.\\\\ml-1m/README',\n",
       " '.\\\\ml-1m/users.dat']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyensae\n",
    "url = \"http://files.grouplens.org/datasets/movielens/\"\n",
    "file = \"ml-1m.zip\"\n",
    "pyensae.download_data(file, website=url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ml-1m', 'ml-1m.zip']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pyensae\n",
    "[ _ for _ in os.listdir() if \"ml\" in _ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ici on charge les données puis on les stocke dans un dictionnaire\n",
    "from itertools import islice\n",
    "\n",
    "lines = np.genfromtxt('ml-1m/ratings.dat', delimiter=\"::\", dtype=None)\n",
    "my_dict = dict()\n",
    "for i in range(len(lines)):\n",
    "   my_dict[lines[i][0],lines[i][1]] = lines[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[((822, 1620), 4), ((2488, 1459), 3), ((3389, 423), 2), ((4305, 508), 4), ((1163, 3752), 3), ((2895, 3070), 5), ((3780, 2916), 5), ((3308, 185), 3), ((3029, 296), 5), ((1151, 1265), 4)]\n"
     ]
    }
   ],
   "source": [
    "# Nous avons ((userID, movieID), rating)\n",
    "\n",
    "def take(n, iterable): \n",
    "     return list(islice(iterable,n))\n",
    "print(take(10, my_dict.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 822 1620    4]\n",
      " [2488 1459    3]\n",
      " [3389  423    2]\n",
      " ..., \n",
      " [2628 2240    2]\n",
      " [5762 2085    4]\n",
      " [2895 3173    3]]\n"
     ]
    }
   ],
   "source": [
    "### ICI on crée la matrice sparse R des ratings\n",
    "\n",
    "import json\n",
    "from pandas import Series,DataFrame\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "data = []\n",
    "row = []\n",
    "col = []\n",
    "for k, v in my_dict.items():\n",
    "    k=np.asarray(k)\n",
    "    r = int(k[0])\n",
    "    c = int(k[1])\n",
    "    data.append(v)\n",
    "    row.append(r)\n",
    "    col.append(c)\n",
    "R = sparse.coo_matrix((data,(row,col)))\n",
    "\n",
    "\n",
    "# Et on la met sous forme de trois colonnes indice_ligne, indice_colonne, valeur\n",
    "\n",
    "data=np.array([R.row, R.col, R.data])\n",
    "data=np.transpose(data)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Attention il faut executer cette fenêtre deux fois (la premiere fois une erreur apparaît)\n",
    "\n",
    "# Ici on créé les matrices P et Q dont le produit doit approximer R.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', header = None,sep=\"::\",engine=\"python\")\n",
    "ratings.columns=['user_id','item_id', 'rating', 'timestamp']\n",
    "ratings=ratings[['user_id','item_id', 'rating']]\n",
    "#Series(df.values.ravel()).unique()\n",
    "m=len(Series(ratings['user_id'].values.ravel()).unique()) #m nb d'users\n",
    "n=len(Series(ratings['item_id'].values.ravel()).unique()) #n nb d'items\n",
    "\n",
    "# Nous les codons de la même manière que data, c'est-à-dire sous forme de trois colonnes.\n",
    "# Ces matrices sont initialisées avec des nombres aléatoires entre 0 et 1.\n",
    "\n",
    "d=10 # dimension latente\n",
    "\n",
    "# P est de dimension m*d\n",
    "\n",
    "p=np.random.uniform(0,1,((m*d)))\n",
    "row_p=[x for x in Series(ratings['user_id'].values.ravel()).unique() for j in range(0,10)]\n",
    "col_int=[  i for j in range(0,m) for i in range(1,11) ]\n",
    "P = sparse.coo_matrix((p,(row_p,col_int)))\n",
    "matrix_p=np.array([P.row, P.col, P.data])\n",
    "matrix_p=np.transpose(matrix_p)\n",
    "\n",
    "# q est de dimension n*d\n",
    "\n",
    "q=np.random.uniform(0,1,((n*d)))\n",
    "row_q=[x for x in Series(ratings['item_id'].values.ravel()).unique() for j in range(0,10)]\n",
    "col_int=[ i for j in range(0,n) for i in range(1,11)]\n",
    "Q = sparse.coo_matrix((q,(row_q,col_int)))\n",
    "matrix_q=np.array([Q.row, Q.col, Q.data])\n",
    "matrix_q=np.transpose(matrix_q)\n",
    "\n",
    "np.savetxt(\"sparse_matrix.csv\", data, delimiter=\",\")\n",
    "np.savetxt(\"matrix_p.csv\", matrix_p, delimiter=\",\")\n",
    "np.savetxt(\"matrix_q.csv\", matrix_q, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$PSEUDO/projet_DM/data_full.csv'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_up sparse_matrix.csv /$PSEUDO/projet_DM/data_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$PSEUDO/projet_DM/matrix_p_full.csv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_up matrix_p.csv /$PSEUDO/projet_DM/matrix_p_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$PSEUDO/projet_DM/matrix_q_full.csv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_up matrix_q.csv /$PSEUDO/projet_DM/matrix_q_full.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>last_modified</th>\n",
       "      <th>content_type</th>\n",
       "      <th>content_length</th>\n",
       "      <th>blob_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xaviermf/projet_DM/data_full.csv</td>\n",
       "      <td>Wed, 15 Jul 2015 22:55:22 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>75015675</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xaviermf/projet_DM/matrix_p_full.csv</td>\n",
       "      <td>Wed, 15 Jul 2015 22:56:19 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>4530000</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xaviermf/projet_DM/matrix_q_full.csv</td>\n",
       "      <td>Wed, 15 Jul 2015 22:56:52 GMT</td>\n",
       "      <td>application/octet-stream</td>\n",
       "      <td>2779500</td>\n",
       "      <td>BlockBlob</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   name                  last_modified  \\\n",
       "0      xaviermf/projet_DM/data_full.csv  Wed, 15 Jul 2015 22:55:22 GMT   \n",
       "1  xaviermf/projet_DM/matrix_p_full.csv  Wed, 15 Jul 2015 22:56:19 GMT   \n",
       "2  xaviermf/projet_DM/matrix_q_full.csv  Wed, 15 Jul 2015 22:56:52 GMT   \n",
       "\n",
       "               content_type  content_length  blob_type  \n",
       "0  application/octet-stream        75015675  BlockBlob  \n",
       "1  application/octet-stream         4530000  BlockBlob  \n",
       "2  application/octet-stream         2779500  BlockBlob  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%blob_ls /$PSEUDO/projet_DM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_factorization (R, P, Q, K, steps =100 , gamma =0.02 , lambd =0.02) :\n",
    "    Q = Q.T\n",
    "    # update des matrices P et Q\n",
    "    for step in range ( steps ):\n",
    "        for i in range (len (R)):\n",
    "            for j in range (len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    eij = R[i][j] - np.dot (P[i ,:] ,Q[:,j])\n",
    "                    for k in range (K):\n",
    "                        P[i][k] = P[i][k] + gamma * (2 * eij * Q[k][j] - lambd * P[i][k])\n",
    "                        Q[k][j] = Q[k][j] + gamma * (2 * eij * P[i][k] - lambd * Q[k][j])\n",
    "        eR = np.dot (P,Q)\n",
    "        e = 0\n",
    "        # calcul de la fonction de cout\n",
    "        for i in range (len (R)):\n",
    "            for j in range (len(R[i])):\n",
    "                if R[i][j] > 0:\n",
    "                    e = e + pow (R[i][j] - np.dot(P[i ,:] ,Q[:,j]) , 2)\n",
    "                    for k in range (K):\n",
    "                        e = e + ( lambd /2) * ( pow(P[i][k] ,2) + pow (Q[k][j] ,2) )\n",
    "        if e < 0.001:\n",
    "            break\n",
    "    return P, Q.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalement, comme le décrit le code python ci-dessous, pour réaliser la mise à jour de $p_{ik}$ on\n",
    "doit se déplacer sur l'ensemble des colonnes $j$ de $Q$ : en effet, à $j$ fixé, il faut mettre à jour $p_{ik}$ en\n",
    "ajoutant la contribution du coefficient $q_{kj}$ à l'erreur ; la prochaine fois que $p_{ik}$ sera modifié, c'est\n",
    "lorsque l'on sera passé à la colonne suivante $j+1$ et que l'on ajoutera la contribution du coefficient\n",
    "$q_{k,j+1}$ à l'erreur. Cette modification à trois boucles sur $i$, $j$, $k$ à été pour nous un vrai-casse tête\n",
    "à implémenter en PIG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons finalement choisi de mettre à jour $P$ puis $Q$. Pour ce faire, nous avons d'abord calculé tous les termes \n",
    "$\\gamma e_{ij}q_{kj}$ puis les nouvelles valeurs d'une manière plus simple : $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \\sum_{j=1}^n \\gamma e_{ij}q_{kj}$. De la même manière, nous avons mis à jour $Q$ avec les coefficients de $P$ mis à jour. Nous sommes conscients que cette façon de modifier les coefficients n'est pas équivalente à la première mais c'est la meilleure solution que nous ayons trouvée. Pour nos expériences, nous avons d'abord testé notre code sur les 100 premières lignes de la base de données, qui contiennent les notes de 2 utilisateurs sur 99 films, et avons regardé la distance euclidienne qui sépare $R$ et $PQ$ sur trois itérations (les calculs étaient déjà relativement lents)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l'implémentation de cette méthode en Pig, nous nous sommes aperçus d'une divergence du produit $PQ$ par rapport à la matrice $R$ : la somme des coefficients au carré de $R-PQ$ était de 418 après initialisation de $P$ et $Q$ avec une loi uniforme sur $[0, 1]$, puis de 1070 après une itération et de 2893 après deux itérations. Le problème provient vraisemblablement de la mise à jour de $P$ et $Q$ car la méthode est différente de celle présentée en Python. De plus l'implémentation en Pig ne donne pas les résultats escomptés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons alors testé une autre méthode, où nous avons calculé indépendemment les termes $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \n",
    "\\gamma e_{ij}q_{kj}$ pour $j$ variant de 1 à $n$ et avons fait la moyenne : $p_{ik} = p_{ik}(1-\\lambda\\gamma) + \\frac{1}{n}\\sum_{j=1}^n \\gamma e_{ij}q_{kj}$. Au bout d'une itération, la distance entre $R$ et $PQ$ est de 349.58, au bout de deux itérations 289.54. La méthode est convergente, que ce soit pour un échantillon réduit d'utilisateurs ou pour l'ensemble de la base de données (100 000 notes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En effet, nous avons lancé le calcul en Pig sur les données initiales et en près de deux heures, nous avons obtenu après 3 itérations la distance euclidienne des matrices $PQ$ successives à la matrice $R$. Par souci de clarté dans le code, nous n'avons pas fait figurer davantage d'itérations sachant qu'il s'agit de copier-collers supplémentaires (car Pig ne gère pas les boucles). La distance euclidienne après 0, 1 et 2 vaut respectivement, pour l'ensemble de la base de données 2,9.10^6, 2,6.10^6, 2,2.10^6. La distance semble converger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implémentation PIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%PIG matrix_factorization2.pig\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "--                                               Iteration 0\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On charge les matrices R, P et Q;\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "R = LOAD '$CONTAINER/$PSEUDO/projet_DM/data_full.csv' USING PigStorage(',') AS (userID:int,movieID:int,rate:double);\n",
    "P = LOAD '$CONTAINER/$PSEUDO/projet_DM/matrix_p_full.csv' USING PigStorage(',') AS (userID:int, latent_p:int, val_p:double);\n",
    "Q = LOAD '$CONTAINER/$PSEUDO/projet_DM/matrix_q_full.csv' USING PigStorage(',') AS (movieID:int, latent_q:int, val_q:double);\n",
    "\n",
    "--DUMP P ;\n",
    "--DUMP Q ;\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On calcule le produit matriciel entre P et Q\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivant joint P et Q \n",
    "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
    "\n",
    "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
    "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
    "\n",
    "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
    "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
    "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
    "\n",
    "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
    "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
    "\n",
    "\n",
    "----------------------------------------------------------------\n",
    "-- On calcule lerreur  et lerreur au carre\n",
    "----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivante joint les matrices R et PQ \n",
    "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
    "\n",
    "\n",
    "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
    "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
    "\n",
    "-- syntaxe pour sommer = group all au lieu de group by\n",
    "\n",
    "resultat_group = GROUP E ALL ;\n",
    "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
    "DUMP resultat ;\n",
    "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_0' using PIGStorage(',','-schema') ; \n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "--                                               Iteration 1\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On met a jour P et Q\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "-- Tout dabord on joint les matrices E et P\n",
    "E_and_P = JOIN E BY userID_2, P BY userID ;\n",
    "E_and_P_bis = FOREACH E_and_P GENERATE userID, movieID_2, latent_p, error,  val_p ;\n",
    "\n",
    "-- On joint ensuite le resultat avec Q\n",
    "E_and_P_and_Q = JOIN E_and_P_bis BY (movieID_2, latent_p), Q BY (movieID, latent_q) ;\n",
    "\n",
    "\n",
    "-------------- Mise a jour de P et Q\n",
    "\n",
    "-- On calcule la matrice des gamma*e_ij*q_kj (qui vont servir a la mise a jour des p_ik) et des p_ik\n",
    "P_update1 = FOREACH E_and_P_and_Q GENERATE userID, movieID, latent_p, error, (val_p*(1-$lamb*$gamma)+$gamma*error*val_q) AS val_p, val_q; \n",
    "Q_update1 = FOREACH P_update1 GENERATE userID, movieID, latent_p AS latent_q, error, val_p, (val_q*(1-$lamb*$gamma)+$gamma*error*val_p) AS val_q ; \n",
    "\n",
    "P_group = GROUP P_update1 by (userID, latent_p) ;\n",
    "P_new = FOREACH P_group GENERATE group, AVG(P_update1.val_p) AS val_p ;\n",
    "P = FOREACH P_new GENERATE FLATTEN(group) AS (userID, latent_p), val_p ;\n",
    "--STORE P into '$CONTAINER/$PSEUDO/projet_DM/matrix_p_1' using PIGStorage(',','-schema') ; \n",
    "\n",
    "\n",
    "-- Idem pour Q\n",
    "Q_group = GROUP Q_update1 by (movieID, latent_q) ;\n",
    "Q_new = FOREACH Q_group GENERATE group, AVG(Q_update1.val_q) AS val_q ;\n",
    "Q = FOREACH Q_new GENERATE FLATTEN(group) AS (movieID, latent_q), val_q ;\n",
    "--STORE Q into '$CONTAINER/$PSEUDO/projet_DM/matrix_q_1' using PIGStorage(',','-schema') ; \n",
    "\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On calcule le produit matriciel entre P et Q\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivant joint P et Q \n",
    "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
    "\n",
    "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
    "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
    "\n",
    "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
    "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
    "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
    "\n",
    "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
    "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
    "\n",
    "\n",
    "----------------------------------------------------------------\n",
    "-- On calcule lerreur  et lerreur au carre\n",
    "----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivante joint les matrices R et PQ \n",
    "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
    "\n",
    "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
    "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
    "\n",
    "\n",
    "-- syntaxe pour sommer = group all au lieu de group by\n",
    "\n",
    "resultat_group = GROUP E ALL ;\n",
    "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
    "DUMP resultat ;\n",
    "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_1' using PIGStorage(',','-schema') ; \n",
    "\n",
    "\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "--                                               Iteration 2\n",
    "----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On met a jour P et Q\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "-- Tout dabord on joint les matrices E et P\n",
    "E_and_P = JOIN E BY userID_2, P BY userID ;\n",
    "E_and_P_bis = FOREACH E_and_P GENERATE userID, movieID_2, latent_p, error,  val_p ;\n",
    "\n",
    "-- On joint ensuite le resultat avec Q\n",
    "E_and_P_and_Q = JOIN E_and_P_bis BY (movieID_2, latent_p), Q BY (movieID, latent_q) ;\n",
    "\n",
    "\n",
    "-------------- Mise a jour de P et Q\n",
    "\n",
    "-- On calcule la matrice des gamma*e_ij*q_kj (qui vont servir a la mise a jour des p_ik) et des p_ik\n",
    "P_update1 = FOREACH E_and_P_and_Q GENERATE userID, movieID, latent_p, error, (val_p*(1-$lamb*$gamma)+$gamma*error*val_q) AS val_p, val_q; \n",
    "Q_update1 = FOREACH P_update1 GENERATE userID, movieID, latent_p AS latent_q, error, val_p, (val_q*(1-$lamb*$gamma)+$gamma*error*val_p) AS val_q ; \n",
    "\n",
    "P_group = GROUP P_update1 by (userID, latent_p) ;\n",
    "P_new = FOREACH P_group GENERATE group, AVG(P_update1.val_p) AS val_p ;\n",
    "P = FOREACH P_new GENERATE FLATTEN(group) AS (userID, latent_p), val_p ;\n",
    "--STORE P into '$CONTAINER/$PSEUDO/projet_DM/matrix_p_2' using PIGStorage(',','-schema') ; \n",
    "\n",
    "-- Idem pour Q\n",
    "Q_group = GROUP Q_update1 by (movieID, latent_q) ;\n",
    "Q_new = FOREACH Q_group GENERATE group, AVG(Q_update1.val_q) AS val_q ;\n",
    "Q = FOREACH Q_new GENERATE FLATTEN(group) AS (movieID, latent_q), val_q ;\n",
    "--STORE Q into '$CONTAINER/$PSEUDO/projet_DM/matrix_q_2' using PIGStorage(',','-schema') ; \n",
    "\n",
    "-----------------------------------------------------------------\n",
    "-- On calcule le produit matriciel entre P et Q\n",
    "-----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivant joint P et Q \n",
    "P_and_Q = JOIN P BY latent_p, Q BY latent_q ;\n",
    "\n",
    "-- La commande suivante calcule tous les pik*qkj ou i=userID et j=movieID\n",
    "P_x_Q = FOREACH P_and_Q GENERATE userID, movieID, latent_p, val_p*val_q AS produit ;\n",
    "\n",
    "-- Ici on groupe tous les termes pik*qkj avec le meme couple(i,j) pour pouvoir sommer sur les k variables latentes\n",
    "grouped_P_x_Q = GROUP P_x_Q by (userID, movieID) ;\n",
    "calcul_PQ = FOREACH grouped_P_x_Q GENERATE group, SUM(P_x_Q.produit) AS ps ;\n",
    "\n",
    "-- Ici on recupere la matrice PQ :(i,j, ligne pi*colonneqj)\n",
    "PQ = FOREACH calcul_PQ GENERATE FLATTEN(group) AS (userID_2, movieID_2), ps ;\n",
    "\n",
    "\n",
    "----------------------------------------------------------------\n",
    "-- On calcule lerreur  et lerreur au carre\n",
    "----------------------------------------------------------------\n",
    "\n",
    "-- La commande suivante joint les matrices R et PQ \n",
    "R_and_PQ = JOIN R BY (userID, movieID), PQ BY (userID_2, movieID_2) ;\n",
    "\n",
    "-- Dans cette matrice on calcule lerreur au carre faite sur chaque coefficient de R \n",
    "E = FOREACH R_and_PQ GENERATE userID_2, movieID_2, (rate-ps) AS error, (rate-ps)*(rate-ps) AS error_sq ;\n",
    "\n",
    "\n",
    "-- syntaxe pour sommer = group all au lieu de group by\n",
    "\n",
    "resultat_group = GROUP E ALL ;\n",
    "resultat = FOREACH resultat_group GENERATE SUM(E.error_sq) ;\n",
    "DUMP resultat ;\n",
    "--STORE resultat into '$CONTAINER/$PSEUDO/projet_DM/resultat_iteration_2' using PIGStorage(',','-schema') ; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'job_1435385350894_0101'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.pig_submit(bs, \n",
    "                  client.account_name, \n",
    "                  \"matrix_factorization2.pig\", \n",
    "                  params = dict(gamma=\"0.02\", lamb=\"0.02\"), \n",
    "                  stop_on_failure=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('job_1435385350894_0101', '21% complete', False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = %hd_job_status job_1435385350894_0101\n",
    "st[\"id\"],st[\"percentComplete\"],st[\"status\"][\"jobComplete\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>\n",
       "\n",
       "</pre><br />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%tail_stderr job_1435385350894_0101 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%blob_downmerge /$PSEUDO/projet_DM/matrix_p_1 matrix_p_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%blob_downmerge /$PSEUDO/projet_DM/matrix_p_2 matrix_p_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%blob_downmerge /$PSEUDO/projet_DM/matrix_q_1 matrix_q_1.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%blob_downmerge /$PSEUDO/projet_DM/matrix_q_2 matrix_q_2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import matrix_coo\n",
    "\n",
    "matrix_p_1 = open(\"matrix_p_1.csv\",\"r\").read()\n",
    "matrix_p_2 = open(\"matrix_p_2.csv\",\"r\").read()\n",
    "matrix_q_1 = open(\"matrix_q_1.csv\",\"r\").read()\n",
    "matrix_q_2 = open(\"matrix_q_2.csv\",\"r\").read()\n",
    "\n",
    "matrix_p_1 = matrix_coo(matrix_p_1).toarray()\n",
    "matrix_p_2 = matrix_coo(matrix_p_2).toarray()\n",
    "matrix_q_1 = matrix_coo(matrix_q_1).toarray()\n",
    "matrix_q_2 = matrix_coo(matrix_q_2).toarray()\n",
    "\n",
    "#mettre R, P, Q sous forme \"normale\" (depuis sparse)\n",
    "\n",
    "\n",
    "PQ_1 = np.dot(matrix_p_1, matrix_q_1.T)\n",
    "PQ_2 = np.dot(matrix_p_2, matrix_q_2.T)\n",
    "\n",
    "#Erreurs au carre\n",
    "print(np.sum((R-PQ_1)**2))\n",
    "print(np.sum((R-PQ_2)**2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
